import torch
import torch.nn as nn
import numpy as np
from PIL import Image

import os
import matplotlib.pyplot as plt  # ç”¨äºå›¾åƒå¯è§†åŒ–ï¼ˆç¡®è®¤é¢„å¤„ç†æ•ˆæœï¼‰


# -------------------------- 1. å®šä¹‰ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´çš„æ¨¡å‹ï¼ˆå¿…é¡»å’Œè®­ç»ƒä»£ç åŒ¹é…ï¼‰ --------------------------
def create_model():
    """
    æ³¨æ„ï¼šæ­¤æ¨¡å‹ç»“æ„å¿…é¡»å’Œè®­ç»ƒæ—¶å®Œå…¨ç›¸åŒï¼
    è®­ç»ƒæ—¶å·²åˆ é™¤æœ€åä¸€å±‚Softmaxï¼ˆå› CrossEntropyLosså†…ç½®ï¼‰ï¼Œé¢„æµ‹æ—¶éœ€ä¿ç•™Softmaxè¾“å‡ºæ¦‚ç‡
    """
    model = nn.Sequential(
        nn.Linear(784, 444),  # 28Ã—28=784ä¸ªè¾“å…¥ç‰¹å¾
        nn.ReLU(),  # æ¿€æ´»å‡½æ•°
        nn.Linear(444, 512),  # éšè—å±‚1
        nn.ReLU(),
        nn.Linear(512, 512),  # éšè—å±‚2
        nn.ReLU(),
        nn.Linear(512, 10),  # 10ä¸ªè¾“å‡ºï¼ˆå¯¹åº”0-9ï¼‰
        nn.Softmax(dim=1)  # é¢„æµ‹æ—¶ä¿ç•™ï¼Œå°†è¾“å‡ºè½¬ä¸ºæ¦‚ç‡ï¼ˆdim=1ç¡®ä¿æŒ‰è¡Œå½’ä¸€åŒ–ï¼‰
    )
    return model


# -------------------------- 2. å›¾åƒé¢„å¤„ç†ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šåè‰²+äºŒå€¼åŒ–ï¼Œç¡®ä¿åŒ¹é…MNISTæ ¼å¼ï¼‰ --------------------------
def preprocess_image(image_path, need_invert=True, threshold=150):
    """
    å›¾åƒé¢„å¤„ç†ï¼šè¯»å–â†’ç°åº¦â†’ç¼©æ”¾â†’åè‰²â†’äºŒå€¼åŒ–â†’å½’ä¸€åŒ–â†’å±•å¹³
    å‚æ•°è¯´æ˜ï¼š
        - image_path: æ‰‹å†™ç…§ç‰‡è·¯å¾„
        - need_invert: æ˜¯å¦éœ€è¦åè‰²ï¼ˆTrue=é»‘åº•ç™½å­—â†’ç™½åº•é»‘å­—ï¼›False=å·²ç™½åº•é»‘å­—ï¼Œæ— éœ€åè‰²ï¼‰
        - threshold: äºŒå€¼åŒ–é˜ˆå€¼ï¼ˆ100-200å¯è°ƒï¼Œæ•°å­—æ¨¡ç³Šåˆ™å‡å°ï¼ŒèƒŒæ™¯æ‚åˆ™å¢å¤§ï¼‰
    """
    # 1. éªŒè¯è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"âŒ å›¾ç‰‡æ–‡ä»¶ä¸å­˜åœ¨ï¼š{image_path}")

    # 2. è¯»å–å›¾åƒå¹¶è½¬ç°åº¦å›¾ï¼ˆMNISTæ˜¯å•é€šé“ç°åº¦å›¾ï¼‰
    img = Image.open(image_path).convert('L')  # 'L'æ¨¡å¼=ç°åº¦å›¾

    # 3. ç¼©æ”¾ä¸º28Ã—28ï¼ˆMNISTæ ‡å‡†å°ºå¯¸ï¼‰ï¼ŒæŠ—é”¯é½¿æ’å€¼é¿å…å¤±çœŸ
    img_resized = img.resize((28, 28), Image.Resampling.LANCZOS)

    # 4. è½¬ä¸ºnumpyæ•°ç»„ï¼Œä¾¿äºåç»­å¤„ç†
    img_np = np.array(img_resized, dtype=np.float32)

    # 5. åè‰²å¤„ç†ï¼ˆå…³é”®ï¼šMNISTè¦æ±‚â€œç™½åº•é»‘å­—â€ï¼‰
    if need_invert:
        img_np = 255.0 - img_np  # é»‘åº•ç™½å­— â†’ ç™½åº•é»‘å­—ï¼ˆåƒç´ å€¼åè½¬ï¼š255â†’0ï¼Œ0â†’255ï¼‰

    # 6. äºŒå€¼åŒ–ï¼ˆæ ¸å¿ƒï¼šå¼ºåˆ¶åˆ†ç¦»æ•°å­—å’ŒèƒŒæ™¯ï¼Œè§£å†³æ¨¡ç³Šé—®é¢˜ï¼‰
    # å¤§äºé˜ˆå€¼â†’çº¯ç™½èƒŒæ™¯ï¼ˆ255ï¼‰ï¼Œå°äºç­‰äºé˜ˆå€¼â†’çº¯é»‘æ•°å­—ï¼ˆ0ï¼‰
    img_np[img_np > threshold] = 255.0
    img_np[img_np <= threshold] = 0.0

    # 7. å½’ä¸€åŒ–ï¼ˆMNISTè®­ç»ƒæ—¶åƒç´ å€¼å·²å½’ä¸€åŒ–åˆ°0-1ï¼Œä¿æŒä¸€è‡´ï¼‰
    img_normalized = img_np / 255.0  # æ­¤æ—¶ï¼šèƒŒæ™¯=1ï¼Œæ•°å­—=0

    # 8. å±•å¹³ä¸º784ç»´å‘é‡ï¼ˆåŒ¹é…æ¨¡å‹è¾“å…¥ï¼š(1, 784)ï¼Œ1ä¸ªæ ·æœ¬+784ä¸ªç‰¹å¾ï¼‰
    img_flatten = img_normalized.reshape(1, 784)

    # 9. å¯è§†åŒ–é¢„å¤„ç†è¿‡ç¨‹ï¼ˆå…³é”®ï¼šç¡®è®¤æ¯ä¸€æ­¥æ˜¯å¦æ­£ç¡®ï¼‰
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei']  # è§£å†³ä¸­æ–‡æ˜¾ç¤º
    plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºå¼‚å¸¸
    fig, axes = plt.subplots(1, 3, figsize=(12, 4))  # 1è¡Œ3åˆ—å­å›¾

    # åŸå§‹ç¼©æ”¾å›¾
    axes[0].imshow(img_resized, cmap='gray')
    axes[0].set_title(f'1. åŸå§‹ç¼©æ”¾å›¾\n(28Ã—28åƒç´ )')
    axes[0].axis('off')  # éšè—åæ ‡è½´

    # åè‰²åå›¾
    axes[1].imshow(img_np, cmap='gray')
    axes[1].set_title(f'2. åè‰²+äºŒå€¼åŒ–å\n(é˜ˆå€¼={threshold})')
    axes[1].axis('off')

    # æœ€ç»ˆè¾“å…¥æ¨¡å‹å›¾ï¼ˆå½’ä¸€åŒ–åï¼‰
    axes[2].imshow(img_normalized, cmap='gray')
    axes[2].set_title(f'3. æœ€ç»ˆè¾“å…¥æ¨¡å‹å›¾\n(åƒç´ å€¼0-1)')
    axes[2].axis('off')

    plt.tight_layout()
    plt.show()  # å¼¹å‡ºçª—å£æ˜¾ç¤ºé¢„å¤„ç†æ•ˆæœ

    # 10. è½¬ä¸ºTensorå¹¶é€‚é…è®¾å¤‡ï¼ˆGPU/CPUï¼‰
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    img_tensor = torch.tensor(img_flatten).to(device)

    return img_tensor


# -------------------------- 3. åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡ --------------------------
def load_trained_model(model_path):
    """
    åŠ è½½æ¨¡å‹æƒé‡ï¼šåˆå§‹åŒ–æ¨¡å‹â†’åŠ è½½æƒé‡â†’åˆ‡æ¢ä¸ºè¯„ä¼°æ¨¡å¼
    """
    # 1. ç¡®è®¤æ¨¡å‹è·¯å¾„å­˜åœ¨
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼š{model_path}")

    # 2. é€‚é…è®¾å¤‡ï¼ˆä¼˜å…ˆGPUï¼Œæ— åˆ™CPUï¼‰
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"âœ… ä½¿ç”¨è®¾å¤‡ï¼š{device}")

    # 3. åˆå§‹åŒ–æ¨¡å‹å¹¶åŠ è½½æƒé‡
    model = create_model().to(device)
    # map_location=deviceï¼šè‡ªåŠ¨é€‚é…å½“å‰è®¾å¤‡ï¼ˆé¿å…è®­ç»ƒç”¨GPUã€é¢„æµ‹ç”¨CPUçš„è®¾å¤‡ä¸åŒ¹é…é—®é¢˜ï¼‰
    model.load_state_dict(torch.load(model_path, map_location=device))

    # 4. åˆ‡æ¢ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­Dropoutç­‰è®­ç»ƒç‰¹æœ‰çš„å±‚ï¼Œä¸å½±å“å½“å‰æ¨¡å‹ï¼Œä½†å¿…é¡»å…»æˆä¹ æƒ¯ï¼‰
    model.eval()
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼š{model_path}")

    return model, device


# -------------------------- 4. æ ¸å¿ƒé¢„æµ‹å‡½æ•° --------------------------
def predict_handwritten_digit(image_path, model_path, need_invert=True, threshold=150):
    """
    å®Œæ•´é¢„æµ‹æµç¨‹ï¼šåŠ è½½æ¨¡å‹â†’é¢„å¤„ç†å›¾åƒâ†’æ¨ç†é¢„æµ‹â†’è¾“å‡ºç»“æœ
    """
    try:
        # 1. åŠ è½½æ¨¡å‹
        model, device = load_trained_model(model_path)

        # 2. é¢„å¤„ç†å›¾åƒï¼ˆå¾—åˆ°æ¨¡å‹å¯è¯†åˆ«çš„Tensorï¼‰
        img_tensor = preprocess_image(image_path, need_invert, threshold)

        # 3. æ¨ç†é¢„æµ‹ï¼ˆå…³é—­æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœæ˜¾å­˜å’Œæ—¶é—´ï¼‰
        with torch.no_grad():
            output = model(img_tensor)  # æ¨¡å‹è¾“å‡ºï¼š(1, 10)ï¼Œ1ä¸ªæ ·æœ¬çš„10ä¸ªæ•°å­—æ¦‚ç‡
            predicted_prob, predicted_label = torch.max(output, dim=1)  # å–æ¦‚ç‡æœ€å¤§çš„æ ‡ç­¾

        # 4. è¾“å‡ºç»“æœ
        print("\n" + "=" * 50)
        print(f"ğŸ“Š è¯†åˆ«ç»“æœï¼šæ•°å­— {predicted_label.item()}")
        print(f"ğŸ“ˆ ç½®ä¿¡åº¦ï¼š{predicted_prob.item():.4f}")  # ç½®ä¿¡åº¦=è¯¥æ•°å­—çš„æ¦‚ç‡ï¼ˆè¶Šé«˜è¶Šå¯ä¿¡ï¼‰
        print(f"ğŸ“‹ æ‰€æœ‰æ•°å­—æ¦‚ç‡åˆ†å¸ƒï¼š")
        for i in range(10):
            print(f"   æ•°å­—{i}ï¼š{output[0][i].item():.4f}")
        print("=" * 50)

        return predicted_label.item(), predicted_prob.item()

    except Exception as e:
        print(f"\nâŒ è¯†åˆ«å¤±è´¥ï¼š{str(e)}")
        return None, None


# -------------------------- 5. ä¸€é”®æ‰§è¡Œè¯†åˆ«ï¼ˆä¿®æ”¹è·¯å¾„å³å¯ç”¨ï¼‰ --------------------------
if __name__ == "__main__":
    # -------------------------- è¯·æ ¹æ®ä½ çš„å®é™…æƒ…å†µä¿®æ”¹ä»¥ä¸‹2ä¸ªè·¯å¾„ï¼ --------------------------
    # 1. æ‰‹å†™æ•°å­—ç…§ç‰‡è·¯å¾„ï¼ˆæ”¯æŒpng/jpg/jpegæ ¼å¼ï¼Œç”¨rå‰ç¼€é¿å…è½¬ä¹‰é—®é¢˜ï¼‰
    HANDWRITTEN_IMAGE_PATH = r"D:/ä¸‹è½½/QQ Flies/4.png"  # ä½ çš„æ‰‹å†™ç…§ç‰‡è·¯å¾„
    # 2. è®­ç»ƒå¥½çš„æ¨¡å‹æƒé‡è·¯å¾„ï¼ˆè®­ç»ƒæ—¶ä¿å­˜çš„mymodel.ptè·¯å¾„ï¼‰
    TRAINED_MODEL_PATH = r"./data/mymodel.pt"  # ä½ çš„æ¨¡å‹è·¯å¾„

    # -------------------------- å¯é€‰å‚æ•°è°ƒæ•´ï¼ˆæ ¹æ®é¢„å¤„ç†å›¾åƒæ•ˆæœä¿®æ”¹ï¼‰ --------------------------
    NEED_INVERT = True  # æ˜¯å¦éœ€è¦åè‰²ï¼šçœ‹é¢„å¤„ç†å›¾2æ˜¯å¦ä¸ºâ€œç™½åº•é»‘å­—â€ï¼Œä¸æ˜¯åˆ™æ”¹True
    THRESHOLD = 120  # äºŒå€¼åŒ–é˜ˆå€¼ï¼šæ•°å­—æ¨¡ç³Šâ†’å‡å°ï¼ˆå¦‚120ï¼‰ï¼ŒèƒŒæ™¯æœ‰æ‚ç‚¹â†’å¢å¤§ï¼ˆå¦‚180ï¼‰

    # æ‰§è¡Œè¯†åˆ«
    predict_handwritten_digit(
        image_path=HANDWRITTEN_IMAGE_PATH,
        model_path=TRAINED_MODEL_PATH,
        need_invert=NEED_INVERT,
        threshold=THRESHOLD
    )
